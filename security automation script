# scripts/scan-runner.py
#!/usr/bin/env python3
"""
Centralized security scan orchestrator that runs various security tools
and aggregates results into a standardized format.
"""

import argparse
import json
import logging
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("scan-runner")

# Define supported scanners
SUPPORTED_SCANNERS = {
    "sast": ["bandit", "semgrep", "sonarqube"],
    "dast": ["zap", "burpsuite"],
    "sca": ["safety", "dependency-check", "snyk"],
    "iac": ["tfsec", "checkov", "kics"],
    "container": ["trivy", "clair", "grype"],
    "secret": ["gitleaks", "trufflehog"]
}

class ScanRunner:
    def __init__(self, scan_type, target_path, output_dir, config_file=None):
        self.scan_type = scan_type
        self.target_path = Path(target_path).resolve()
        self.output_dir = Path(output_dir).resolve()
        self.config_file = Path(config_file).resolve() if config_file else None
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Create output directory if it doesn't exist
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def run_sast_scan(self):
        """Run Static Application Security Testing tools"""
        logger.info(f"Running SAST scan on {self.target_path}")
        
        # Run Bandit for Python code security analysis
        bandit_output = self.output_dir / f"bandit_results_{self.timestamp}.json"
        try:
            subprocess.run(
                ["bandit", "-r", str(self.target_path), "-f", "json", "-o", str(bandit_output)],
                check=True
            )
            logger.info(f"Bandit scan completed successfully: {bandit_output}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Bandit scan failed: {e}")
        except FileNotFoundError:
            logger.error("Bandit not found. Please install it with 'pip install bandit'")
            
        # Run Semgrep with OWASP ruleset
        semgrep_output = self.output_dir / f"semgrep_results_{self.timestamp}.json"
        try:
            subprocess.run(
                ["semgrep", "--config=p/owasp-top-ten", str(self.target_path), 
                 "--json", "-o", str(semgrep_output)],
                check=True
            )
            logger.info(f"Semgrep scan completed successfully: {semgrep_output}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Semgrep scan failed: {e}")
        except FileNotFoundError:
            logger.error("Semgrep not found. Please install it with 'pip install semgrep'")
    
    def run_dependency_scan(self):
        """Run Software Composition Analysis for dependencies"""
        logger.info(f"Running dependency scan for {self.target_path}")
        
        # Find requirements files
        req_files = list(self.target_path.glob("**/requirements*.txt"))
        if not req_files:
            logger.warning("No requirements files found for dependency scanning")
            return
            
        # Run Safety for Python dependency scanning
        for req_file in req_files:
            safety_output = self.output_dir / f"safety_results_{req_file.stem}_{self.timestamp}.json"
            try:
                subprocess.run(
                    ["safety", "check", "-r", str(req_file), "--json", "-o", str(safety_output)],
                    check=True
                )
                logger.info(f"Safety scan completed successfully for {req_file}: {safety_output}")
            except subprocess.CalledProcessError as e:
                logger.error(f"Safety scan failed for {req_file}: {e}")
            except FileNotFoundError:
                logger.error("Safety not found. Please install it with 'pip install safety'")
                break
    
    def run_iac_scan(self):
        """Run Infrastructure as Code security scans"""
        logger.info(f"Running IaC security scan on {self.target_path}")
        
        # Run tfsec for Terraform security scanning
        terraform_dirs = list(self.target_path.glob("**/terraform"))
        if terraform_dirs:
            tfsec_output = self.output_dir / f"tfsec_results_{self.timestamp}.json"
            try:
                subprocess.run(
                    ["tfsec", "--format", "json", "-o", str(tfsec_output), str(terraform_dirs[0])],
                    check=True
                )
                logger.info(f"tfsec scan completed successfully: {tfsec_output}")
            except subprocess.CalledProcessError as e:
                logger.error(f"tfsec scan failed: {e}")
            except FileNotFoundError:
                logger.error("tfsec not found. Please install it")
        else:
            logger.warning("No Terraform directories found for IaC scanning")
    
    def run_container_scan(self):
        """Run container security scans"""
        logger.info("Running container security scan")
        
        # Find Dockerfiles
        dockerfiles = list(self.target_path.glob("**/Dockerfile"))
        if not dockerfiles:
            logger.warning("No Dockerfiles found for container scanning")
            return
            
        # Run Trivy for container scanning
        for dockerfile in dockerfiles:
            # Build the Docker image for scanning
            image_name = f"security-scan-{dockerfile.parent.name}:latest"
            try:
                subprocess.run(
                    ["docker", "build", "-t", image_name, "-f", str(dockerfile), str(dockerfile.parent)],
                    check=True
                )
                
                # Scan the built image
                trivy_output = self.output_dir / f"trivy_results_{dockerfile.parent.name}_{self.timestamp}.json"
                subprocess.run(
                    ["trivy", "image", "--format", "json", "--output", str(trivy_output), image_name],
                    check=True
                )
                logger.info(f"Trivy scan completed successfully for {dockerfile}: {trivy_output}")
            except subprocess.CalledProcessError as e:
                logger.error(f"Container scan failed for {dockerfile}: {e}")
            except FileNotFoundError as e:
                logger.error(f"Required tool not found: {e}")
                break

    def run_secret_scan(self):
        """Run secret detection scans"""
        logger.info(f"Running secret detection scan on {self.target_path}")
        
        # Run Gitleaks for secret detection
        gitleaks_output = self.output_dir / f"gitleaks_results_{self.timestamp}.json"
        try:
            subprocess.run(
                ["gitleaks", "detect", "--source", str(self.target_path), 
                 "--report-format", "json", "--report-path", str(gitleaks_output)],
                check=True
            )
            logger.info(f"Gitleaks scan completed successfully: {gitleaks_output}")
        except subprocess.CalledProcessError as e:
            logger.error(f"Gitleaks scan failed: {e}")
        except FileNotFoundError:
            logger.error("Gitleaks not found. Please install it")
    
    def run_scan(self):
        """Run the appropriate scan based on scan_type"""
        if self.scan_type == "sast":
            self.run_sast_scan()
        elif self.scan_type == "sca":
            self.run_dependency_scan()
        elif self.scan_type == "iac":
            self.run_iac_scan()
        elif self.scan_type == "container":
            self.run_container_scan()
        elif self.scan_type == "secret":
            self.run_secret_scan()
        elif self.scan_type == "all":
            self.run_sast_scan()
            self.run_dependency_scan()
            self.run_iac_scan()
            self.run_container_scan()
            self.run_secret_scan()
        else:
            logger.error(f"Unsupported scan type: {self.scan_type}")
            return False
        
        return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Security Scan Runner")
    parser.add_argument("--type", choices=list(SUPPORTED_SCANNERS.keys()) + ["all"], required=True,
                        help="Type of security scan to run")
    parser.add_argument("--target", default=".", help="Target directory to scan")
    parser.add_argument("--output", default="./scan-results", help="Output directory for scan results")
    parser.add_argument("--config", help="Path to configuration file")
    args = parser.parse_args()
    
    runner = ScanRunner(args.type, args.target, args.output, args.config)
    success = runner.run_scan()
    
    sys.exit(0 if success else 1)


# scripts/report-generator.py
#!/usr/bin/env python3
"""
Security findings report generator that consolidates results from
multiple security scanning tools into a unified format.
"""

import argparse
import json
import logging
import os
from datetime import datetime
from pathlib import Path

import jinja2
import pandas as pd
import matplotlib.pyplot as plt
from tabulate import tabulate

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("report-generator")

class ReportGenerator:
    def __init__(self, scan_results_dir, output_dir, report_format="html"):
        self.scan_results_dir = Path(scan_results_dir)
        self.output_dir = Path(output_dir)
        self.report_format = report_format
        self.timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        
        # Create output directory if it doesn't exist
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Setup templates
        template_dir = Path(__file__).parent.parent / "config" / "report-templates"
        self.jinja_env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(str(template_dir)),
            autoescape=jinja2.select_autoescape(['html', 'xml'])
        )
    
    def _parse_bandit_results(self, file_path):
        """Parse Bandit JSON results into a standardized format"""
        findings = []
        
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                
            for result in data.get('results', []):
                findings.append({
                    'tool': 'Bandit',
                    'severity': result.get('issue_severity', 'Unknown'),
                    'type': result.get('issue_text', 'Unknown'),
                    'file': result.get('filename', 'Unknown'),
                    'line': result.get('line_number', 0),
                    'description': result.get('issue_text', 'Unknown'),
                    'cwe': result.get('cwe', 'Unknown'),
                    'fix': result.get('more_info', 'See Bandit documentation')
                })
        except Exception as e:
            logger.error(f"Error parsing Bandit results {file_path}: {e}")
            
        return findings
    
    def _parse_semgrep_results(self, file_path):
        """Parse Semgrep JSON results into a standardized format"""
        findings = []
        
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                
            for result in data.get('results', []):
                findings.append({
                    'tool': 'Semgrep',
                    'severity': result.get('extra', {}).get('severity', 'Unknown'),
                    'type': result.get('check_id', 'Unknown'),
                    'file': result.get('path', 'Unknown'),
                    'line': result.get('start', {}).get('line', 0),
                    'description': result.get('extra', {}).get('message', 'Unknown'),
                    'cwe': result.get('extra', {}).get('metadata', {}).get('cwe', 'Unknown'),
                    'fix': result.get('extra', {}).get('fix', 'See rule documentation')
                })
        except Exception as e:
            logger.error(f"Error parsing Semgrep results {file_path}: {e}")
            
        return findings
    
    def _parse_trivy_results(self, file_path):
        """Parse Trivy JSON results into a standardized format"""
        findings = []
        
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                
            for result in data.get('Results', []):
                for vuln in result.get('Vulnerabilities', []):
                    findings.append({
                        'tool': 'Trivy',
                        'severity': vuln.get('Severity', 'Unknown'),
                        'type': 'Vulnerable Package',
                        'file': f"{vuln.get('PkgName', 'Unknown')}:{vuln.get('InstalledVersion', 'Unknown')}",
                        'line': 0,
                        'description': vuln.get('Title', 'Unknown'),
                        'cwe': vuln.get('CweIDs', ['Unknown'])[0] if vuln.get('CweIDs') else 'Unknown',
                        'fix': f"Update to {vuln.get('FixedVersion', 'latest version')}"
                    })
        except Exception as e:
            logger.error(f"Error parsing Trivy results {file_path}: {e}")
            
        return findings
    
    def _parse_safety_results(self, file_path):
        """Parse Safety JSON results into a standardized format"""
        findings = []
        
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                
            for vuln in data.get('vulnerabilities', []):
                findings.append({
                    'tool': 'Safety',
                    'severity': vuln.get('severity', 'Unknown'),
                    'type': 'Vulnerable Package',
                    'file': f"{vuln.get('package_name', 'Unknown')}:{vuln.get('analyzed_version', 'Unknown')}",
                    'line': 0,
                    'description': vuln.get('advisory', 'Unknown'),
                    'cwe': 'CWE-1035',  # Vulnerable Third-Party Component
                    'fix': f"Update to {vuln.get('fixed_version', 'latest version')}"
                })
        except Exception as e:
            logger.error(f"Error parsing Safety results {file_path}: {e}")
            
        return findings
    
    def collect_findings(self):
        """Collect and parse findings from all scan result files"""
        all_findings = []
        
        # Process all result files in the scan results directory
        for file_path in self.scan_results_dir.glob('**/*.json'):
            file_name = file_path.name.lower()
            
            if 'bandit' in file_name:
                findings = self._parse_bandit_results(file_path)
            elif 'semgrep' in file_name:
                findings = self._parse_semgrep_results(file_path)
            elif 'trivy' in file_name:
                findings = self._parse_trivy_results(file_path)
            elif 'safety' in file_name:
                findings = self._parse_safety_results(file_path)
            else:
                logger.warning(f"Unsupported scan result file: {file_path}")
                continue
                
            all_findings.extend(findings)
            logger.info(f"Processed {len(findings)} findings from {file_path}")
            
        return all_findings
    
    def generate_statistics(self, findings):
        """Generate statistics from findings"""
        stats = {
            'total_findings': len(findings),
            'by_severity': {},
            'by_tool': {},
            'by_type': {}
        }
        
        # Create a DataFrame for easier analysis
        df = pd.DataFrame(findings)
        
        # Count by severity
        severity_counts = df['severity'].value_counts().to_dict()
        stats['by_severity'] = severity_counts
        
        # Count by tool
        tool_counts = df['tool'].value_counts().to_dict()
        stats['by_tool'] = tool_counts
        
        # Count by vulnerability type
        type_counts = df['type'].value_counts().to_dict()
        stats['by_type'] = {k: v for k, v in type_counts.items() if v >= 3}  # Only include common types
        
        return stats
    
    def generate_charts(self, stats):
        """Generate charts from statistics"""
        charts_dir = self.output_dir / 'charts'
        charts_dir.mkdir(exist_ok=True)
        chart_files = []
        
        # Create severity pie chart
        plt.figure(figsize=(8, 5))
        severities = stats['by_severity']
        plt.pie(severities.values(), labels=severities.keys(), autopct='%1.1f%%', 
                colors=['red', 'orange', 'yellow', 'blue', 'green'])
        plt.title('Findings by Severity')
        severity_chart = charts_dir / f'severity_pie_{self.timestamp}.png'
        plt.savefig(severity_chart)
        plt.close()
        chart_files.append(severity_chart)
        
        # Create tools bar chart
        plt.figure(figsize=(10, 6))
        tools = stats['by_tool']
        plt.bar(tools.keys(), tools.values())
        plt.title('Findings by Tool')
        plt.xlabel('Tool')
        plt.ylabel('Number of Findings')
        plt.xticks(rotation=45)
        tool_chart = charts_dir / f'tool_bar_{self.timestamp}.png'
        plt.savefig(tool_chart)
        plt.close()
        chart_files.append(tool_chart)
        
        return chart_files
        
    def generate_html_report(self, findings, stats, chart_files):
        """Generate HTML report from findings"""
        template = self.jinja_env.get_template('report.html.j2')
        
        # Prepare data for template
        template_data = {
            'report_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'findings': findings,
            'stats': stats,
            'charts': [str(f.relative_to(self.output_dir)) for f in chart_files],
            'high_severity_count': stats['by_severity'].get('High', 0) + stats['by_severity'].get('Critical', 0),
            'medium_severity_count': stats['by_severity'].get('Medium', 0),
            'low_severity_count': stats['by_severity'].get('Low', 0),
        }
        
        # Render template
        html_content = template.render(**template_data)
        
        # Write to file
        report_file = self.output_dir / f'security_report_{self.timestamp}.html'
        with open(report_file, 'w') as f:
            f.write(html_content)
            
        logger.info(f"HTML report generated: {report_file}")
        return report_file
        
    def generate_markdown_report(self, findings, stats):
        """Generate Markdown report from findings"""
        report_file = self.output_dir / f'security_report_{self.timestamp}.md'
        
        with open(report_file, 'w') as f:
            # Write header
            f.write(f"# Security Scan Report\n\n")
            f.write(f"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Write summary
            f.write("## Summary\n\n")
            f.write(f"Total findings: {stats['total_findings']}\n\n")
            
            # Write severity breakdown
            f.write("### Findings by Severity\n\n")
            severity_table = [["Severity", "Count"]]
            for severity, count in stats['by_severity'].items():
                severity_table.append([severity, count])
            f.write(tabulate(severity_table, headers="firstrow", tablefmt="pipe"))
            f.write("\n\n")
            
            # Write findings table
            f.write("## Detailed Findings\n\n")
            findings_table = [["Severity", "Tool", "Type", "Location", "Description"]]
            
            # Sort findings by severity (Critical, High, Medium, Low)
            severity_order = {"Critical": 0, "High": 1, "Medium": 2, "Low": 3, "Unknown": 4}
            sorted_findings = sorted(findings, 
                                    key=lambda x: severity_order.get(x['severity'], 5))
            
            for finding in sorted_findings:
                findings_table.append([
                    finding['severity'],
                    finding['tool'],
                    finding['type'],
                    f"{finding['file']}:{finding['line']}",
                    finding['description']
                ])
            
            f.write(tabulate(findings_table, headers="firstrow", tablefmt="pipe"))
            
        logger.info(f"Markdown report generated: {report_file}")
        return report_file
    
    def generate_report(self):
        """Generate a comprehensive security report"""
        # Collect all findings
        findings = self.collect_findings()
        if not findings:
            logger.warning("No findings collected. Report will be empty.")
        
        # Generate statistics
        stats = self.generate_statistics(findings)
        
        # Generate charts
        chart_files = self.generate_charts(stats)
        
        # Generate report in requested format
        if self.report_format == 'html':
            return self.generate_html_report(findings, stats, chart_files)
        elif self.report_format == 'markdown':
            return self.generate_markdown_report(findings, stats)
        else:
            logger.error(f"Unsupported report format: {self.report_format}")
            return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Security Report Generator")
    parser.add_argument("--results-dir", default="./scan-results", 
                        help="Directory containing scan results")
    parser.add_argument("--output-dir", default="./reports", 
                        help="Directory to output reports")
    parser.add_argument("--format", choices=["html", "markdown
